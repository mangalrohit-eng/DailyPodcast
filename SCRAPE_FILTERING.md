# Scrape Filtering - Only Use Successfully Scraped Stories

## Overview

Your podcast now **filters out stories where web scraping failed** before creating the episode. Only stories with successfully scraped full article content make it into your podcast.

---

## What Changed

### Before
```
Ranking â†’ 8 stories selected
   â†“
Scraping â†’ 5 successful, 3 failed
   â†“
Outline â†’ Uses all 8 stories (some with only RSS summaries)
   â†“
Scriptwriting â†’ Mixed quality (some stories lack depth)
```

### After
```
Ranking â†’ 8 stories selected
   â†“
Scraping â†’ 5 successful, 3 failed
   â†“
Filter â†’ Remove 3 failed scrapes
   â†“
Outline â†’ Uses only 5 successfully scraped stories
   â†“
Scriptwriting â†’ High quality (all stories have full content)
```

---

## Why This Matters

### Quality Improvement

**Before:**
- Stories with failed scrapes had only RSS summaries (100-300 chars)
- Scripts were shallow and lacked detail
- Uneven quality across different stories in same episode

**After:**
- All stories have full article content (2000-10000 chars)
- Scripts are detailed and meaty
- Consistent high quality throughout episode

### Example

**Story with Failed Scrape:**
```
RSS Summary: "OpenAI announces new model. More details coming soon."
Script: "OpenAI announced a new model today." (shallow)
```

**Story with Successful Scrape:**
```
Full Article: "OpenAI today unveiled GPT-5, featuring improved reasoning capabilities, 
multi-modal support, and significant performance improvements. The model was trained on 
100 trillion tokens and shows 40% improvement in benchmark tests. CEO Sam Altman stated..."
Script: "OpenAI has unveiled GPT-5, their most advanced model yet. The new system features 
dramatically improved reasoning capabilities and can now handle multiple data types seamlessly. 
Trained on an unprecedented 100 trillion tokens, GPT-5 shows a 40% jump in benchmark 
performance. CEO Sam Altman emphasized..."
```

---

## How It Works

### Filtering Logic

Location: `lib/orchestrator.ts` lines 338-357

```typescript
// Filter out picks where scraping failed - only use successfully scraped stories
const successfullyScrapedPicks = scraperResult.output.enriched_picks.filter(pick => {
  // A pick is successfully scraped if it has meaningful raw content (>500 chars)
  return pick.story.raw && pick.story.raw.length > 500;
});

const filteredCount = scraperResult.output.enriched_picks.length - successfullyScrapedPicks.length;

if (filteredCount > 0) {
  Logger.info(`Filtered out ${filteredCount} stories with failed scrapes`, {
    original_count: scraperResult.output.enriched_picks.length,
    successfully_scraped: successfullyScrapedPicks.length,
    filtered_out: filteredCount,
  });
}

// Check if we have enough stories after filtering
if (successfullyScrapedPicks.length === 0) {
  throw new Error('No stories successfully scraped - cannot create episode without content');
}
```

### Success Criteria

A story is considered "successfully scraped" if:
- âœ… `story.raw` field exists (contains full article text)
- âœ… `story.raw.length > 500` (has meaningful content, not just headers)

### Failure Cases

Stories are filtered out if:
- âŒ Scraping failed (network error, timeout, blocked)
- âŒ Content extraction failed (couldn't parse HTML)
- âŒ Content too short (<500 chars)
- âŒ Paywall or authentication required

---

## Impact on Episode Generation

### Story Count

**Before:**
- Ranking selects 8-12 stories
- All 8-12 used in episode (regardless of scrape success)

**After:**
- Ranking selects 8-12 stories
- Only successfully scraped stories used in episode
- **Typically 5-8 stories** in final episode (60-80% scrape success rate)

### Episode Length

The system automatically adjusts:
- **Fewer stories** â†’ Each story gets more time
- Target duration maintained (e.g., 15 minutes)
- Better depth rather than breadth

### Edge Case: Too Few Stories

If **all scrapes fail**:
```
Error: No stories successfully scraped - cannot create episode without content
```

The episode generation will fail rather than create a low-quality episode.

**Prevention:**
- Use high-quality sources (Tiers 1, 2, 4) - better scraping success
- Google News often works well (already resolved to actual articles)
- Increase story count in ranking to have buffer

---

## Logging & Visibility

### Console Logs

```
âœ… Scraping complete
   successful: 6
   failed: 2
   avg_length: 4521

â„¹ï¸ Filtered out 2 stories with failed scrapes
   original_count: 8
   successfully_scraped: 6
   filtered_out: 2
```

### Pipeline Report

The scraping report still shows all attempts:

```json
{
  "scraper": {
    "total_articles": 8,
    "successful_scrapes": 6,
    "failed_scrapes": [
      {
        "url": "https://example.com/article",
        "reason": "HTTP 403 Forbidden"
      },
      {
        "url": "https://paywall-site.com/premium",
        "reason": "Content too short or empty"
      }
    ],
    "avg_content_length": 4521,
    "all_scrape_attempts": [...]
  }
}
```

But only the 6 successfully scraped stories are used in the outline and script.

---

## Why Scraping Might Fail

### Common Reasons

1. **Paywalls** (WSJ, NYT premium articles)
   - Site requires subscription
   - Shows only preview/teaser
   
2. **Bot Protection** (Cloudflare, reCAPTCHA)
   - Site blocks automated scraping
   - Requires JavaScript/cookies
   
3. **Network Issues**
   - Timeout (>10 seconds)
   - DNS failure
   - Connection refused
   
4. **Dynamic Content**
   - Content loaded by JavaScript
   - Requires browser rendering
   
5. **Malformed HTML**
   - Can't extract main content
   - Ads/navigation confused as content

### Scrape Success Rates by Source Type

Based on typical behavior:

| Source Type | Success Rate | Notes |
|------------|--------------|-------|
| Google News (resolved) | ~85% | Usually works well |
| Tier 1 News (Reuters, AP) | ~80% | Professional sites, usually accessible |
| Tier 2 Tech (TechCrunch) | ~75% | Sometimes have paywalls |
| Corporate Sites | ~90% | Simple, accessible |
| Unknown/Blogs | ~50% | Variable quality/protection |

---

## Benefits

### 1. Consistent Quality
- All stories have full context
- No "thin" segments with limited info
- Professional-sounding podcast

### 2. Better Scripts
- Scriptwriter has rich material to work with
- Can include specific details, quotes, data
- More engaging narrative

### 3. Accurate Information
- Full articles provide context
- Avoid misinterpretation from summaries
- Better fact-checking possible

### 4. Clear Expectations
- If episode succeeds, you know all content is high-quality
- If episode fails, you know scraping was the issue
- Transparency in content quality

---

## Customization

### Adjust Minimum Content Length

Current threshold: **500 characters**

To change it:

```typescript
// More lenient (accept shorter content)
return pick.story.raw && pick.story.raw.length > 300;

// More strict (require longer content)
return pick.story.raw && pick.story.raw.length > 1000;
```

### Allow Stories Without Scraping

To disable filtering (use all stories, scraped or not):

```typescript
// Comment out the filter
// const successfullyScrapedPicks = scraperResult.output.enriched_picks.filter(pick => {
//   return pick.story.raw && pick.story.raw.length > 500;
// });

// Use all picks instead
const successfullyScrapedPicks = scraperResult.output.enriched_picks;
```

### Hybrid Approach

Use only scraped stories, but if too few, fall back to some non-scraped:

```typescript
const successfullyScrapedPicks = scraperResult.output.enriched_picks.filter(pick => {
  return pick.story.raw && pick.story.raw.length > 500;
});

// If less than 3 successful, add back some failed ones
if (successfullyScrapedPicks.length < 3) {
  const failedPicks = scraperResult.output.enriched_picks.filter(pick => {
    return !pick.story.raw || pick.story.raw.length <= 500;
  });
  successfullyScrapedPicks.push(...failedPicks.slice(0, 3 - successfullyScrapedPicks.length));
}
```

---

## Testing

### Verify Filtering Works

1. **Generate an episode**:
   ```bash
   npm run dev
   # Trigger episode generation
   ```

2. **Check the logs**:
   Look for:
   ```
   Filtered out X stories with failed scrapes
   ```

3. **Review pipeline report**:
   - Scraping report shows all attempts
   - But outline/script only use successfully scraped stories

4. **Check script quality**:
   - All story segments should be detailed
   - No thin/shallow segments

---

## Related Systems

### Story Selection Pipeline

```
1. Ingestion â†’ Fetch from RSS feeds
2. Tier Filtering â†’ Only Tier 1, 2, 4 sources
3. Ranking â†’ Score and select top stories
4. Scraping â†’ Fetch full article content
5. âœ¨ Scrape Filtering â†’ Remove failed scrapes (NEW!)
6. Outline â†’ Structure episode
7. Scriptwriting â†’ Write detailed script
8. TTS â†’ Generate audio
```

Each filter improves quality while reducing quantity.

---

## Files Modified

### `lib/orchestrator.ts`

**Lines 338-357** - Added scrape filtering logic:
- Filter enriched picks by raw content length
- Log filtering statistics
- Error if no stories successfully scraped
- Pass only successful picks to outline agent

**Line 368** - Changed from:
```typescript
picks: scraperResult.output.enriched_picks,
```
To:
```typescript
picks: successfullyScrapedPicks, // Use ONLY successfully scraped picks
```

---

## Summary

**What Changed:**
- âœ… Added filtering after scraping phase
- âœ… Only stories with full article content (>500 chars) proceed
- âœ… Failed scrapes are tracked but not used
- âœ… Error if all scrapes fail

**Result:**
- ğŸ¯ Consistent high-quality episodes
- ğŸ“ Detailed, meaty scripts
- ğŸ™ï¸ Professional-sounding podcast
- âš ï¸ Fewer stories per episode (but better quality)

**Trade-off:**
- Episodes may have 5-8 stories instead of 8-12
- But each story is covered in much greater depth
- Overall better listening experience

